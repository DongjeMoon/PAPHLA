# Data paths
train_data: "data/train/train_ptm.csv"
val_data: "data/train/val_ptm.csv"

# Model configuration
model:
  dim_h: 32
  dim_pe: 16
  dim_esm: 320  # ESM-2 8M model embedding dimension
  max_len: 15
  steps: 16
  num_seeds: 1
  num_heads: 4
  dropout: 0.1
  attn_dropout: 0.5
  n_gps_layers: 4
  n_crs_layers: 3
  residual: true
  use_rdb: true
  pool: "PMA" # or "mean"

# Finetuning configuration
training:
  batch_size: 256
  epochs: 20
  patience: 5
  seed: 42
  model_name: "PAPHLA_finetune"
  model_weight: "PAPHLA_pretrain"
  finetune: true

dro:
  is_robust: true
  alpha: 0.15
  normalize_loss: true
  btl: true
  step_size: 0.02
